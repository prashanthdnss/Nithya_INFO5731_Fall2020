{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashanthdnss/Nithya_INFO5731_Fall2020/blob/master/In_class_exercise/In_class_exercise_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR"
      },
      "source": [
        "# **The sixth in-class-exercise (20 points in total, 10/14/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh"
      },
      "source": [
        "## **1. Rule-based information extraction (10 points)**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvR_O9D8sOUY",
        "outputId": "e29e6631-e646-4610-abcc-792e1d1a7798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "# Write your code here\n",
        "titles = open(\"results.txt\").read()\n",
        "titles\n",
        "\n",
        "#Explanation of how titles were scrapped:\n",
        "#I have used beautifulsoup and extracted first page of google scholar and titles with keyword \"k-means clustering\". So, i extracted for next 10 pages into a text file and hence upload. \n",
        "#Still working on how to extract all 10 pages together."
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Constrained k-means clustering with background knowledge. The global k-means clustering algorithm. An efficient k-means clustering algorithm: Analysis and implementation. Web-scale k-means clustering. K-means clustering via principal component analysis. An efficient k-means clustering algorithm. Refining initial points for k-means clustering. Spectral relaxation for k-means clustering\\n\\nParallel K-Means Clustering Based on MapReduce\\n\\n[PDF][PDF] Constrained k-means clustering\\n\\n\\nAlgorithm AS 136: A k-means clustering algorithm\\n\\nImage segmentation using K-means clustering algorithm and subtractive clustering algorithm\\n\\nCluster center initialization algorithm for K-means clustering\\n\\nK‐means clustering: a half‐century synthesis\\n\\nAn efficient k′-means clustering algorithm\\n\\nResearch on k-means clustering algorithm: An improved k-means clustering algorithm\\n\\nSelection of K in K-means clustering\\n\\n Improving the Accuracy and Efficiency of the k-means Clustering Algorithm\\n\\nStrong consistency of k-means clustering\\n\\n Review on determining number of Cluster in K-Means Clustering\\n\\n\\nMedical image segmentation using k-means clustering and improved watershed algorithm\\n\\nFeature Weighting in k-Means Clustering\\n\\nPrivacy-preserving k-means clustering over vertically partitioned data\\n\\nAn efficient enhanced k-means clustering algorithm\\n\\n[PDF][PDF] Determination of number of clusters in k-means clustering and application in colour image segmentation\\n\\nKernel density estimation and K-means clustering to profile road accident hotspots\\n\\nLatent class models for clustering: A comparison with K-means\\n\\nA comparative study of efficient initialization methods for the k-means clustering algorithm\\n\\nOn coresets for k-means and k-median clustering\\n\\nA recommender system using GA K-means clustering in an online shopping market\\n\\n\\nA local search approximation algorithm for k-means clustering\\n\\nUnsupervised Change Detection in Satellite Images Using Principal Component Analysis and -Means Clustering\\n\\nEfficient online spherical k-means clustering\\n\\nSpherical k-means clustering\\n\\nAn entropy weighting k-means algorithm for subspace clustering of high-dimensional sparse data\\n\\n[PDF][PDF] K-means clustering tutorial\\n\\n[PDF][PDF] Multi-view k-means clustering on big data\\n\\nK-means clustering versus validation measures: a data-distribution perspective\\n\\n[PDF][PDF] Traffic anomaly detection using k-means clustering\\n\\nFast adaptive k-means clustering: some empirical results\\n\\n\\n\\nFGKA: A fast genetic k-means clustering algorithm\\n\\nPrivacy-preserving distributed k-means clustering over arbitrarily partitioned data\\n\\nAgglomerative fuzzy k-means clustering algorithm with selection of number of clusters\\n\\nk∗-Means: A new generalized k-means clustering algorithm\\n\\n[HTML][HTML] Exploring the conditional coregulation of yeast gene expression through fuzzy k-means clustering\\n\\n[BOOK][B] Advances in K-means clustering: a data mining thinking\\n\\nAdaptive dimension reduction using discriminant analysis and K-means clustering\\n\\nOptimized big data K-means clustering using MapReduce\\n\\nA Central Limit Theorem for -Means Clustering\\n\\nImproved K-means clustering algorithm\\n\\n\\n[PDF][PDF] Smaller coresets for k-median and k-means clustering\\n\\n[PDF][PDF] Enhancing K-means clustering algorithm with improved initial center\\n\\nSecure two-party k-means clustering\\n\\n[BOOK][B] The hardness of k-means clustering\\n\\nA method for initialising the K-means clustering algorithm using kd-trees\\n\\nThe MinMax k-Means clustering algorithm\\n\\nApplication of k Means Clustering algorithm for prediction of Students Academic Performance\\n\\nAdapting the right measures for k-means clustering\\n\\nSelf-organizing maps as substitutes for k-means clustering\\n\\nOptimized data fusion for kernel k-means clustering\\n\\nOpen source clustering software\\n\\n[HTML][HTML] Ckmeans. 1d. dp: optimal k-means clustering in one dimension by dynamic programming\\n\\nAdaptive fuzzy moving K-means clustering algorithm for image segmentation\\n\\nMinkowski metric, feature weighting and anomalous cluster initializing in K-Means clustering\\n\\nA modified K-means clustering algorithm for use in isolated work recognition\\n\\nLocal optima in K-means clustering: what you don't know may hurt you.\\n\\n[PDF][PDF] Standardization and its effects on K-means clustering algorithm\\n\\nEEG signals classification using the K-means clustering and a multilayer perceptron neural network model\\n\\nRandomized Dimensionality Reduction for  -Means Clustering\\n\\nA wavelet-based anytime algorithm for k-means clustering of time series\\n\\n\\n\\nSome refinements of rough k-means clustering\\n\\nAn improved K-Means clustering algorithm\\n\\nConcept lattice reduction using fuzzy K-means clustering\\n\\nBrain tumor detection using color-based k-means clustering segmentation\\n\\n[PDF][PDF] Parallel K-means clustering algorithm on NOWs\\n\\nFast image segmentation based on K-Means clustering with histograms in HSV color space\\n\\nDimensionality reduction for k-means clustering and low rank approximation\\n\\nAdaptive fuzzy-K-means clustering algorithm for image segmentation\\n\\nRandom Projections for -means Clustering\\n\\n[PDF][PDF] Adaptive K-Means Clustering.\\n\\nK-Means+ ID3: A novel method for supervised anomaly detection by cascading K-Means clustering and ID3 decision tree learning methods\\n\\nK-means clustering in wireless sensor networks\\n\\nK-means clustering algorithm with improved initial center\\n\\nOn Coresets for k-Median and k-Means Clustering in Metric and Euclidean Spaces and Their Applications\\n\\nA PTAS for k-means clustering based on weak coresets\\n\\n[PDF][PDF] Image Segmentation using k-means clustering, EM and Normalized Cuts\\n\\nTowards missing data imputation: a study of fuzzy k-means clustering method\\n\\nA genetic algorithm with gene rearrangement for K-means clustering\\n\\n[PDF][PDF] Stability of -Means Clustering\\n\\n[PDF][PDF] A Parallel Implementation of K-Means Clustering on GPUs.\\n\\n\\nK-means clustering over a large, dynamic network\\n\\nIntegrating K-means clustering with a relational DBMS using SQL\\n\\nThe analysis of a simple k-means clustering algorithm\\n\\nRolling element bearing fault detection in industrial environments based on a K-means clustering approach\\n\\nA genetic algorithm that exchanges neighboring centers for k-means clustering\\n\\nAn improved overlapping k-means clustering method for medical applications\\n\\nAn efficient approximation to the K-means clustering for massive data\\n\\nA simple linear time (1+/spl epsiv/)-approximation algorithm for k-means clustering in any dimensions\\n\\nFast and exact out-of-core and distributed k-means clustering\\n\\nNetwork anomaly detection by cascading k-Means clustering and C4. 5 decision tree algorithm\\n\\n\\n\\n\\n\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCiVI7S605pp"
      },
      "source": [
        "import re \n",
        "import string \n",
        "import nltk \n",
        "import spacy \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import math \n",
        "from tqdm import tqdm \n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "from spacy import displacy \n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "# load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmm-WmpQ3HaK",
        "outputId": "931d1160-13da-4699-c77e-3ff8be97b1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "doc = nlp(titles)\n",
        "\n",
        "for tok in doc: \n",
        "  print(tok.text, \"-->\",tok.dep_,\"-->\", tok.pos_)\n",
        "  \n",
        "pattern = [{'POS':'NOUN'}, \n",
        "           {'LOWER': 'clustering'}, \n",
        "           {'POS': 'PROPN'} \n",
        "           ]\n",
        "\n",
        "\n",
        "matcher = Matcher(nlp.vocab) \n",
        "matcher.add(\"matching_1\", None, pattern) \n",
        "matches = matcher(doc) \n",
        "span = doc[matches[0][1]:matches[0][2]] \n",
        "print(span.text)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Constrained --> ROOT --> VERB\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "with --> prep --> ADP\n",
            "background --> compound --> NOUN\n",
            "knowledge --> pobj --> NOUN\n",
            ". --> punct --> PUNCT\n",
            "The --> det --> DET\n",
            "global --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            ". --> punct --> PUNCT\n",
            "An --> det --> DET\n",
            "efficient --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "Analysis --> dobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "implementation --> conj --> NOUN\n",
            ". --> punct --> PUNCT\n",
            "Web --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "scale --> compound --> NOUN\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> nsubj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            ". --> punct --> PUNCT\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> nsubj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            "via --> prep --> ADP\n",
            "principal --> amod --> ADJ\n",
            "component --> compound --> NOUN\n",
            "analysis --> pobj --> NOUN\n",
            ". --> punct --> PUNCT\n",
            "An --> det --> DET\n",
            "efficient --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            ". --> punct --> PUNCT\n",
            "Refining --> amod --> VERB\n",
            "initial --> amod --> ADJ\n",
            "points --> nsubj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            ". --> punct --> PUNCT\n",
            "Spectral --> amod --> ADJ\n",
            "relaxation --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Parallel --> ROOT --> ADJ\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "Means --> compound --> PROPN\n",
            "Clustering --> dobj --> VERB\n",
            "Based --> prep --> VERB\n",
            "on --> prep --> ADP\n",
            "MapReduce --> pobj --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Constrained --> ccomp --> ADJ\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Algorithm --> compound --> PROPN\n",
            "AS --> dobj --> ADP\n",
            "136 --> nummod --> NUM\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> amod --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Image --> compound --> NOUN\n",
            "segmentation --> ROOT --> NOUN\n",
            "using --> acl --> VERB\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> xcomp --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "subtractive --> amod --> ADJ\n",
            "clustering --> amod --> NOUN\n",
            "algorithm --> conj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Cluster --> compound --> NOUN\n",
            "center --> compound --> NOUN\n",
            "initialization --> compound --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "K‐means --> nsubj --> PROPN\n",
            "clustering --> ROOT --> VERB\n",
            ": --> punct --> PUNCT\n",
            "a --> det --> DET\n",
            "half‐century --> compound --> ADJ\n",
            "synthesis --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "An --> det --> DET\n",
            "efficient --> amod --> ADJ\n",
            "k′-means --> nsubj --> NOUN\n",
            "clustering --> amod --> VERB\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Research --> ROOT --> NOUN\n",
            "on --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "An --> det --> DET\n",
            "improved --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> amod --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Selection --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "K --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            "  -->  --> SPACE\n",
            "Improving --> xcomp --> VERB\n",
            "the --> det --> DET\n",
            "Accuracy --> dobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Efficiency --> conj --> PROPN\n",
            "of --> prep --> ADP\n",
            "the --> det --> DET\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "Clustering --> compound --> PROPN\n",
            "Algorithm --> ROOT --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Strong --> amod --> ADJ\n",
            "consistency --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            "  -->  --> SPACE\n",
            "Review --> dobj --> PROPN\n",
            "on --> prep --> ADP\n",
            "determining --> pcomp --> VERB\n",
            "number --> dobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "Cluster --> pobj --> PROPN\n",
            "in --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means --> pobj --> PROPN\n",
            "Clustering --> nmod --> NOUN\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Medical --> amod --> ADJ\n",
            "image --> compound --> NOUN\n",
            "segmentation --> pobj --> NOUN\n",
            "using --> acl --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> amod --> NOUN\n",
            "clustering --> nmod --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "improved --> conj --> VERB\n",
            "watershed --> amod --> ADJ\n",
            "algorithm --> dobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Feature --> compound --> NOUN\n",
            "Weighting --> ROOT --> VERB\n",
            "in --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "Means --> pobj --> PROPN\n",
            "Clustering --> ROOT --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Privacy --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "preserving --> amod --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> dobj --> VERB\n",
            "over --> prep --> ADP\n",
            "vertically --> advmod --> ADV\n",
            "partitioned --> amod --> VERB\n",
            "data --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "An --> det --> DET\n",
            "efficient --> amod --> ADJ\n",
            "enhanced --> amod --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> compound --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Determination --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "number --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "clusters --> pobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> compound --> NOUN\n",
            "clustering --> pobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "application --> conj --> NOUN\n",
            "in --> prep --> ADP\n",
            "colour --> amod --> NOUN\n",
            "image --> compound --> NOUN\n",
            "segmentation --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Kernel --> compound --> NOUN\n",
            "density --> compound --> NOUN\n",
            "estimation --> nsubj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> conj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            "to --> aux --> PART\n",
            "profile --> xcomp --> VERB\n",
            "road --> compound --> NOUN\n",
            "accident --> compound --> NOUN\n",
            "hotspots --> dobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Latent --> compound --> NOUN\n",
            "class --> compound --> NOUN\n",
            "models --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "clustering --> pcomp --> VERB\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "comparison --> ROOT --> NOUN\n",
            "with --> prep --> ADP\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "comparative --> amod --> ADJ\n",
            "study --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "efficient --> amod --> ADJ\n",
            "initialization --> compound --> NOUN\n",
            "methods --> pobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "the --> det --> DET\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> amod --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "On --> prep --> ADP\n",
            "coresets --> pobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "median --> conj --> NOUN\n",
            "clustering --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "recommender --> compound --> NOUN\n",
            "system --> dobj --> NOUN\n",
            "using --> acl --> VERB\n",
            "GA --> compound --> PROPN\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> PROPN\n",
            "clustering --> xcomp --> VERB\n",
            "in --> prep --> ADP\n",
            "an --> det --> DET\n",
            "online --> amod --> ADJ\n",
            "shopping --> compound --> NOUN\n",
            "market --> pobj --> NOUN\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "local --> amod --> ADJ\n",
            "search --> compound --> NOUN\n",
            "approximation --> compound --> NOUN\n",
            "algorithm --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Unsupervised --> ROOT --> VERB\n",
            "Change --> compound --> NOUN\n",
            "Detection --> dobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "Satellite --> compound --> PROPN\n",
            "Images --> pobj --> PROPN\n",
            "Using --> xcomp --> VERB\n",
            "Principal --> compound --> PROPN\n",
            "Component --> compound --> PROPN\n",
            "Analysis --> dobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "-Means --> conj --> PROPN\n",
            "Clustering --> ROOT --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Efficient --> amod --> ADJ\n",
            "online --> amod --> ADJ\n",
            "spherical --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Spherical --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "An --> det --> DET\n",
            "entropy --> amod --> ADJ\n",
            "weighting --> ROOT --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> compound --> NOUN\n",
            "algorithm --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "subspace --> compound --> NOUN\n",
            "clustering --> pobj --> VERB\n",
            "of --> prep --> ADP\n",
            "high --> amod --> ADJ\n",
            "- --> punct --> PUNCT\n",
            "dimensional --> amod --> ADJ\n",
            "sparse --> compound --> ADJ\n",
            "data --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> ROOT --> NOUN\n",
            "tutorial --> dobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Multi --> dep --> PROPN\n",
            "- --> punct --> ADJ\n",
            "view --> compound --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> nsubj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            "on --> prep --> ADP\n",
            "big --> amod --> ADJ\n",
            "data --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "versus --> prep --> ADP\n",
            "validation --> compound --> NOUN\n",
            "measures --> pobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "a --> det --> DET\n",
            "data --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "distribution --> compound --> NOUN\n",
            "perspective --> appos --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Traffic --> compound --> PROPN\n",
            "anomaly --> compound --> PROPN\n",
            "detection --> ROOT --> NOUN\n",
            "using --> acl --> VERB\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> xcomp --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Fast --> advmod --> ADJ\n",
            "adaptive --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> nsubj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            ": --> punct --> PUNCT\n",
            "some --> det --> DET\n",
            "empirical --> amod --> ADJ\n",
            "results --> ROOT --> NOUN\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "FGKA --> appos --> PROPN\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "fast --> advmod --> ADJ\n",
            "genetic --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> compound --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Privacy --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "preserving --> nsubj --> VERB\n",
            "distributed --> ROOT --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "over --> prep --> ADP\n",
            "arbitrarily --> advmod --> ADV\n",
            "partitioned --> amod --> VERB\n",
            "data --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Agglomerative --> amod --> ADJ\n",
            "fuzzy --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "with --> prep --> ADP\n",
            "selection --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "number --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "clusters --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "k∗-Means --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "new --> amod --> ADJ\n",
            "generalized --> amod --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> compound --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "HTML][HTML --> ROOT --> PROPN\n",
            "] --> punct --> PUNCT\n",
            "Exploring --> ROOT --> VERB\n",
            "the --> det --> DET\n",
            "conditional --> amod --> ADJ\n",
            "coregulation --> dobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "yeast --> compound --> NOUN\n",
            "gene --> compound --> NOUN\n",
            "expression --> pobj --> NOUN\n",
            "through --> prep --> ADP\n",
            "fuzzy --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "BOOK][B --> ROOT --> NUM\n",
            "] --> punct --> PUNCT\n",
            "Advances --> nsubj --> NOUN\n",
            "in --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> PROPN\n",
            "clustering --> ROOT --> VERB\n",
            ": --> punct --> PUNCT\n",
            "a --> det --> DET\n",
            "data --> compound --> NOUN\n",
            "mining --> compound --> NOUN\n",
            "thinking --> appos --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Adaptive --> amod --> ADJ\n",
            "dimension --> compound --> NOUN\n",
            "reduction --> ROOT --> NOUN\n",
            "using --> acl --> VERB\n",
            "discriminant --> amod --> ADJ\n",
            "analysis --> dobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> conj --> NOUN\n",
            "clustering --> xcomp --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Optimized --> ROOT --> VERB\n",
            "big --> amod --> ADJ\n",
            "data --> compound --> NOUN\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> NOUN\n",
            "using --> xcomp --> VERB\n",
            "MapReduce --> dobj --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "Central --> compound --> ADJ\n",
            "Limit --> compound --> PROPN\n",
            "Theorem --> ROOT --> PROPN\n",
            "for --> prep --> ADP\n",
            "-Means --> pobj --> PROPN\n",
            "Clustering --> ROOT --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Improved --> compound --> VERB\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> PROPN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> nmod --> PROPN\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> dobj --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Smaller --> amod --> ADJ\n",
            "coresets --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "median --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> conj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Enhancing --> amod --> VERB\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "with --> prep --> ADP\n",
            "improved --> amod --> ADJ\n",
            "initial --> amod --> ADJ\n",
            "center --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Secure --> ROOT --> VERB\n",
            "two --> nummod --> NUM\n",
            "- --> punct --> PUNCT\n",
            "party --> compound --> NOUN\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "BOOK][B --> ROOT --> X\n",
            "] --> punct --> PUNCT\n",
            "The --> det --> DET\n",
            "hardness --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "method --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "initialising --> pcomp --> VERB\n",
            "the --> det --> DET\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> PROPN\n",
            "using --> advcl --> VERB\n",
            "kd --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "trees --> dobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "The --> det --> DET\n",
            "MinMax --> compound --> PROPN\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "Means --> ROOT --> PROPN\n",
            "clustering --> amod --> VERB\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Application --> nsubj --> NOUN\n",
            "of --> prep --> ADP\n",
            "k --> pobj --> PROPN\n",
            "Means --> ROOT --> PROPN\n",
            "Clustering --> compound --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "prediction --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "Students --> compound --> NOUN\n",
            "Academic --> compound --> PROPN\n",
            "Performance --> pobj --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Adapting --> ROOT --> VERB\n",
            "the --> det --> DET\n",
            "right --> amod --> ADJ\n",
            "measures --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Self --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "organizing --> amod --> VERB\n",
            "maps --> dobj --> NOUN\n",
            "as --> prep --> SCONJ\n",
            "substitutes --> pobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Optimized --> amod --> VERB\n",
            "data --> compound --> NOUN\n",
            "fusion --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "kernel --> compound --> PROPN\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Open --> amod --> ADJ\n",
            "source --> nmod --> NOUN\n",
            "clustering --> amod --> VERB\n",
            "software --> dobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "HTML][HTML --> nmod --> PROPN\n",
            "] --> punct --> PUNCT\n",
            "Ckmeans --> ROOT --> PROPN\n",
            ". --> punct --> PUNCT\n",
            "1d --> ROOT --> NUM\n",
            ". --> punct --> PUNCT\n",
            "dp --> ROOT --> PROPN\n",
            ": --> punct --> PUNCT\n",
            "optimal --> compound --> PROPN\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "in --> prep --> ADP\n",
            "one --> nummod --> NUM\n",
            "dimension --> pobj --> NOUN\n",
            "by --> prep --> ADP\n",
            "dynamic --> amod --> ADJ\n",
            "programming --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Adaptive --> advmod --> ADJ\n",
            "fuzzy --> advmod --> ADJ\n",
            "moving --> ROOT --> VERB\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> PROPN\n",
            "clustering --> advcl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "image --> compound --> NOUN\n",
            "segmentation --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Minkowski --> compound --> PROPN\n",
            "metric --> ROOT --> ADJ\n",
            ", --> punct --> PUNCT\n",
            "feature --> compound --> NOUN\n",
            "weighting --> conj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "anomalous --> amod --> ADJ\n",
            "cluster --> conj --> NOUN\n",
            "initializing --> ROOT --> VERB\n",
            "in --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means --> pobj --> PROPN\n",
            "clustering --> advcl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "modified --> amod --> VERB\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "use --> pobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "isolated --> amod --> VERB\n",
            "work --> compound --> NOUN\n",
            "recognition --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Local --> amod --> ADJ\n",
            "optima --> ROOT --> NOUN\n",
            "in --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> PROPN\n",
            "clustering --> ROOT --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "what --> dobj --> PRON\n",
            "you --> nsubj --> PRON\n",
            "do --> aux --> AUX\n",
            "n't --> neg --> PART\n",
            "know --> csubj --> VERB\n",
            "may --> aux --> VERB\n",
            "hurt --> ccomp --> VERB\n",
            "you --> dobj --> PRON\n",
            ". --> punct --> PUNCT\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> PROPN\n",
            "] --> punct --> PUNCT\n",
            "Standardization --> npadvmod --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "its --> poss --> DET\n",
            "effects --> conj --> NOUN\n",
            "on --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> amod --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "EEG --> nsubj --> PROPN\n",
            "signals --> ROOT --> VERB\n",
            "classification --> dobj --> NOUN\n",
            "using --> acl --> VERB\n",
            "the --> det --> DET\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> compound --> NOUN\n",
            "clustering --> dobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "a --> det --> DET\n",
            "multilayer --> amod --> ADJ\n",
            "perceptron --> nmod --> PROPN\n",
            "neural --> amod --> PROPN\n",
            "network --> compound --> NOUN\n",
            "model --> conj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Randomized --> ROOT --> ADJ\n",
            "Dimensionality --> compound --> PROPN\n",
            "Reduction --> dobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "  -->  --> SPACE\n",
            "-Means --> pobj --> PROPN\n",
            "Clustering --> ROOT --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "wavelet --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "based --> amod --> VERB\n",
            "anytime --> det --> NOUN\n",
            "algorithm --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> compound --> NOUN\n",
            "clustering --> pobj --> NOUN\n",
            "of --> prep --> ADP\n",
            "time --> compound --> NOUN\n",
            "series --> pobj --> NOUN\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Some --> det --> DET\n",
            "refinements --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "rough --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "An --> det --> DET\n",
            "improved --> amod --> ADJ\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "Means --> ROOT --> PROPN\n",
            "clustering --> amod --> VERB\n",
            "algorithm --> ROOT --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Concept --> compound --> NOUN\n",
            "lattice --> compound --> NOUN\n",
            "reduction --> ROOT --> NOUN\n",
            "using --> acl --> VERB\n",
            "fuzzy --> amod --> ADJ\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> xcomp --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Brain --> compound --> NOUN\n",
            "tumor --> compound --> NOUN\n",
            "detection --> dobj --> NOUN\n",
            "using --> acl --> VERB\n",
            "color --> npadvmod --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "based --> amod --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> xcomp --> NOUN\n",
            "segmentation --> dobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Parallel --> ROOT --> PROPN\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "on --> prep --> ADP\n",
            "NOWs --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Fast --> amod --> ADJ\n",
            "image --> compound --> NOUN\n",
            "segmentation --> ROOT --> NOUN\n",
            "based --> acl --> VERB\n",
            "on --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means --> pobj --> PROPN\n",
            "clustering --> acl --> VERB\n",
            "with --> prep --> ADP\n",
            "histograms --> pobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "HSV --> compound --> PROPN\n",
            "color --> compound --> NOUN\n",
            "space --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Dimensionality --> compound --> NOUN\n",
            "reduction --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> amod --> NOUN\n",
            "clustering --> amod --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "low --> conj --> ADJ\n",
            "rank --> compound --> NOUN\n",
            "approximation --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Adaptive --> amod --> ADJ\n",
            "fuzzy --> amod --> ADJ\n",
            "- --> punct --> PUNCT\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "image --> compound --> NOUN\n",
            "segmentation --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Random --> compound --> ADJ\n",
            "Projections --> ROOT --> PROPN\n",
            "for --> prep --> ADP\n",
            "-means --> pobj --> NOUN\n",
            "Clustering --> ROOT --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Adaptive --> compound --> ADJ\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means --> compound --> PROPN\n",
            "Clustering --> ROOT --> VERB\n",
            ". --> punct --> PUNCT\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means+ --> dep --> PROPN\n",
            "ID3 --> ROOT --> PROPN\n",
            ": --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "novel --> amod --> ADJ\n",
            "method --> ROOT --> NOUN\n",
            "for --> prep --> ADP\n",
            "supervised --> amod --> VERB\n",
            "anomaly --> compound --> PROPN\n",
            "detection --> pobj --> NOUN\n",
            "by --> prep --> ADP\n",
            "cascading --> pcomp --> VERB\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means --> nsubj --> PROPN\n",
            "clustering --> nmod --> VERB\n",
            "and --> cc --> CCONJ\n",
            "ID3 --> compound --> PROPN\n",
            "decision --> compound --> NOUN\n",
            "tree --> conj --> NOUN\n",
            "learning --> compound --> VERB\n",
            "methods --> dobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "in --> prep --> ADP\n",
            "wireless --> amod --> ADJ\n",
            "sensor --> compound --> NOUN\n",
            "networks --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> ROOT --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "algorithm --> dobj --> NOUN\n",
            "with --> prep --> ADP\n",
            "improved --> amod --> ADJ\n",
            "initial --> amod --> ADJ\n",
            "center --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "On --> prep --> ADP\n",
            "Coresets --> pobj --> PROPN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Median --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means --> conj --> PROPN\n",
            "Clustering --> appos --> VERB\n",
            "in --> prep --> ADP\n",
            "Metric --> nmod --> ADJ\n",
            "and --> cc --> CCONJ\n",
            "Euclidean --> conj --> PROPN\n",
            "Spaces --> pobj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Their --> poss --> DET\n",
            "Applications --> conj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "PTAS --> nsubj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> ROOT --> VERB\n",
            "based --> prep --> VERB\n",
            "on --> prep --> ADP\n",
            "weak --> amod --> ADJ\n",
            "coresets --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Image --> compound --> PROPN\n",
            "Segmentation --> ROOT --> PROPN\n",
            "using --> acl --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> compound --> NOUN\n",
            "clustering --> dobj --> NOUN\n",
            ", --> punct --> PUNCT\n",
            "EM --> conj --> PROPN\n",
            "and --> cc --> CCONJ\n",
            "Normalized --> compound --> PROPN\n",
            "Cuts --> conj --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Towards --> prep --> ADP\n",
            "missing --> pcomp --> VERB\n",
            "data --> compound --> NOUN\n",
            "imputation --> dobj --> NOUN\n",
            ": --> punct --> PUNCT\n",
            "a --> det --> DET\n",
            "study --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "fuzzy --> amod --> ADJ\n",
            "k --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> amod --> NOUN\n",
            "clustering --> compound --> NOUN\n",
            "method --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "genetic --> amod --> ADJ\n",
            "algorithm --> ROOT --> NOUN\n",
            "with --> prep --> ADP\n",
            "gene --> compound --> NOUN\n",
            "rearrangement --> pobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "Stability --> appos --> NOUN\n",
            "of --> prep --> ADP\n",
            "-Means --> pobj --> PROPN\n",
            "Clustering --> ROOT --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "[ --> punct --> PUNCT\n",
            "PDF][PDF --> ROOT --> NOUN\n",
            "] --> punct --> PUNCT\n",
            "A --> det --> DET\n",
            "Parallel --> amod --> ADJ\n",
            "Implementation --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "Means --> compound --> PROPN\n",
            "Clustering --> pobj --> VERB\n",
            "on --> prep --> ADP\n",
            "GPUs --> pobj --> NOUN\n",
            ". --> punct --> PUNCT\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> nsubj --> PROPN\n",
            "clustering --> ROOT --> VERB\n",
            "over --> prep --> ADP\n",
            "a --> det --> DET\n",
            "large --> amod --> ADJ\n",
            ", --> punct --> PUNCT\n",
            "dynamic --> amod --> ADJ\n",
            "network --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Integrating --> ROOT --> VERB\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> dobj --> VERB\n",
            "with --> prep --> ADP\n",
            "a --> det --> DET\n",
            "relational --> amod --> ADJ\n",
            "DBMS --> pobj --> PROPN\n",
            "using --> acl --> VERB\n",
            "SQL --> dobj --> PROPN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "The --> det --> DET\n",
            "analysis --> ROOT --> NOUN\n",
            "of --> prep --> ADP\n",
            "a --> det --> DET\n",
            "simple --> amod --> ADJ\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> amod --> NOUN\n",
            "algorithm --> appos --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Rolling --> compound --> VERB\n",
            "element --> nsubj --> NOUN\n",
            "bearing --> ROOT --> NOUN\n",
            "fault --> compound --> NOUN\n",
            "detection --> dobj --> NOUN\n",
            "in --> prep --> ADP\n",
            "industrial --> amod --> ADJ\n",
            "environments --> pobj --> NOUN\n",
            "based --> acl --> VERB\n",
            "on --> prep --> ADP\n",
            "a --> det --> DET\n",
            "K --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> amod --> NOUN\n",
            "clustering --> compound --> NOUN\n",
            "approach --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "genetic --> amod --> ADJ\n",
            "algorithm --> appos --> NOUN\n",
            "that --> nsubj --> DET\n",
            "exchanges --> relcl --> NOUN\n",
            "neighboring --> compound --> VERB\n",
            "centers --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "An --> det --> DET\n",
            "improved --> nsubj --> ADJ\n",
            "overlapping --> ROOT --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> NOUN\n",
            "method --> dobj --> NOUN\n",
            "for --> prep --> ADP\n",
            "medical --> amod --> ADJ\n",
            "applications --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "An --> det --> DET\n",
            "efficient --> amod --> ADJ\n",
            "approximation --> ROOT --> NOUN\n",
            "to --> prep --> ADP\n",
            "the --> det --> DET\n",
            "K --> compound --> PROPN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> acl --> VERB\n",
            "for --> prep --> ADP\n",
            "massive --> amod --> ADJ\n",
            "data --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "A --> det --> DET\n",
            "simple --> amod --> ADJ\n",
            "linear --> amod --> ADJ\n",
            "time --> ROOT --> NOUN\n",
            "( --> punct --> PUNCT\n",
            "1+/spl --> nummod --> NUM\n",
            "epsiv/)-approximation --> compound --> NOUN\n",
            "algorithm --> nsubj --> NOUN\n",
            "for --> prep --> ADP\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> pobj --> NOUN\n",
            "clustering --> relcl --> VERB\n",
            "in --> prep --> ADP\n",
            "any --> det --> DET\n",
            "dimensions --> pobj --> NOUN\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Fast --> advmod --> ADJ\n",
            "and --> cc --> CCONJ\n",
            "exact --> conj --> VERB\n",
            "out --> advmod --> ADV\n",
            "- --> punct --> PUNCT\n",
            "of --> prep --> ADP\n",
            "- --> punct --> PUNCT\n",
            "core --> pobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "distributed --> conj --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "means --> dobj --> NOUN\n",
            "clustering --> advcl --> VERB\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "Network --> compound --> NOUN\n",
            "anomaly --> compound --> ADP\n",
            "detection --> dobj --> NOUN\n",
            "by --> prep --> ADP\n",
            "cascading --> pcomp --> VERB\n",
            "k --> compound --> NOUN\n",
            "- --> punct --> PUNCT\n",
            "Means --> dobj --> PROPN\n",
            "clustering --> dobj --> NOUN\n",
            "and --> cc --> CCONJ\n",
            "C4 --> conj --> NOUN\n",
            ". --> punct --> PUNCT\n",
            "5 --> nummod --> NUM\n",
            "decision --> compound --> NOUN\n",
            "tree --> ROOT --> NOUN\n",
            "algorithm --> ROOT --> PROPN\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " -->  --> SPACE\n",
            "means Clustering Algorithm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4"
      },
      "source": [
        "## **2. Domain-specific information extraction (10 points)**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc7NtJrLx5tS",
        "outputId": "aeb17b2e-f03e-42a8-8034-f7da044acb72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# write your code here\n",
        "!pip install lexnlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lexnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/d3/2c3f8595eb1aa418d820130e9d4d2b56c82fd2f88f1cb9720983d2f0b4f2/lexnlp-1.7.0-py3-none-any.whl (9.7MB)\n",
            "\u001b[K     |████████████████████████████████| 9.7MB 3.3MB/s \n",
            "\u001b[?25hCollecting dateparser==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/9d/51126ac615bbc4418478d725a5fa1a0f112059f6f111e4b48cfbe17ef9d0/dateparser-0.7.2-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 42.0MB/s \n",
            "\u001b[?25hCollecting datefinder-lexpredict==0.6.2\n",
            "  Downloading https://files.pythonhosted.org/packages/27/47/9a38724045b30e2e4d1c5e3e08fd3b0770dedb2e9ca92c1347b9e2182470/datefinder_lexpredict-0.6.2-py2.py3-none-any.whl\n",
            "Collecting regex==2020.7.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/f2/b3af9ce9df4b7e121dfeece41fc95e37b14f0153821f35d08edb0b0813ff/regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 33.5MB/s \n",
            "\u001b[?25hCollecting reporters-db==2.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/e9/498bada93e69e3162a027d9285e852c464d66aae23ec3c845700ee117414/reporters_db-2.0.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s \n",
            "\u001b[?25hCollecting us==2.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/88/04/04323aefa1871de30286d3decae7706481c73bd428cf0c08e158bfa259a6/us-2.0.2.tar.gz\n",
            "Collecting requests==2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 6.3MB/s \n",
            "\u001b[?25hCollecting num2words==0.5.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.4MB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 36.4MB/s \n",
            "\u001b[?25hCollecting Unidecode==1.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 43.0MB/s \n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 123kB/s \n",
            "\u001b[?25hCollecting pycountry==20.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/73/6f1a412f14f68c273feea29a6ea9b9f1e268177d32e0e69ad6790d306312/pycountry-20.7.3.tar.gz (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 36.7MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 300kB/s \n",
            "\u001b[?25hCollecting scipy==1.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/f9/6eeed6d5cd8dd435bbf105d10d778c2d76de1a5838fdbc315a59fb7fad64/scipy-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 167kB/s \n",
            "\u001b[?25hCollecting nltk==3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 39.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from dateparser==0.7.2->lexnlp) (2018.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from dateparser==0.7.2->lexnlp) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from dateparser==0.7.2->lexnlp) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from reporters-db==2.0.3->lexnlp) (1.15.0)\n",
            "Collecting jellyfish==0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/3f/60ac86fb43dfbf976768e80674b5538e535f6eca5aa7806cf2fdfd63550f/jellyfish-0.6.1.tar.gz (132kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 38.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.24.0->lexnlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.24.0->lexnlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.24.0->lexnlp) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.24.0->lexnlp) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.23.1->lexnlp) (0.16.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words==0.5.10->lexnlp) (0.6.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.3->lexnlp) (2.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk==3.5->lexnlp) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk==3.5->lexnlp) (4.41.1)\n",
            "Building wheels for collected packages: us, pycountry, nltk, jellyfish\n",
            "  Building wheel for us (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for us: filename=us-2.0.2-cp36-none-any.whl size=11928 sha256=9bfc3dfa4a874e448ffddcc5c02f4f56312caae3c52f3ed9c7fc9cf10ddbe18d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/16/45/6453383ffa495670f0f6b80a3e697a9771d98cfbaf8b451e73\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746865 sha256=a9815dc1f743c1fc163458a260a82a99eb468b4bc6cba3f214e191be59673efb\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/4e/a6/be297e6b83567e537bed9df4a93f8590ec01c1acfbcd405348\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434673 sha256=74d0a65ae81016bbac5648e1b74959eb9b471f2bcf985a8003e984a8ef9f7626\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.6.1-cp36-cp36m-linux_x86_64.whl size=74735 sha256=3cfca6540f0c9fad2b67b125dcf923e1097b66e7741f3ebf55c7ee3c9cf47135\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/6f/33/92bb9a4b4562a60ba6a80cedbab8907e48bc7a8b1f369ea0ae\n",
            "Successfully built us pycountry nltk jellyfish\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.5.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datefinder-lexpredict 0.6.2 has requirement regex==2017.9.23, but you'll have regex 2020.7.14 which is incompatible.\u001b[0m\n",
            "Installing collected packages: regex, dateparser, datefinder-lexpredict, reporters-db, jellyfish, us, requests, numpy, threadpoolctl, scipy, scikit-learn, num2words, pandas, Unidecode, gensim, pycountry, nltk, lexnlp\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: pandas 1.1.2\n",
            "    Uninstalling pandas-1.1.2:\n",
            "      Successfully uninstalled pandas-1.1.2\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed Unidecode-1.1.1 datefinder-lexpredict-0.6.2 dateparser-0.7.2 gensim-3.8.3 jellyfish-0.6.1 lexnlp-1.7.0 nltk-3.5 num2words-0.5.10 numpy-1.19.1 pandas-0.24.2 pycountry-20.7.3 regex-2020.7.14 reporters-db-2.0.3 requests-2.24.0 scikit-learn-0.23.1 scipy-1.5.1 threadpoolctl-2.1.0 us-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrYx7QHpqw8P"
      },
      "source": [
        "all_text = open(\"raw_data.txt\").read()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weG2kL6Aq24q",
        "outputId": "61ed8c18-41b2-4b02-b96d-c9f62c82dc55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJRcWH17rP_Q",
        "outputId": "83f18b7e-6625-44ca-fb85-d4be82083d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.acts\n",
        "print(lexnlp.extract.en.acts.get_act_list(all_text))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wqztqtwrd2A",
        "outputId": "6bc66f20-d31e-4075-fe81-b8d7031f7a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import lexnlp.extract.en.amounts\n",
        "list(lexnlp.extract.en.amounts.get_amounts(all_text))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.0,\n",
              " 740.0,\n",
              " 1843.0,\n",
              " 2.0,\n",
              " 1.0,\n",
              " 4.0,\n",
              " 2.0,\n",
              " 1821.0,\n",
              " 5.0,\n",
              " 1.0,\n",
              " 1840.0,\n",
              " 3777,\n",
              " 80.0,\n",
              " 100.0,\n",
              " 30,\n",
              " 1839.0,\n",
              " 741.0,\n",
              " 22,\n",
              " 1840.0,\n",
              " 14000,\n",
              " 120,\n",
              " 1,\n",
              " 1840.0,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 1.0,\n",
              " 1840.0,\n",
              " 2.0,\n",
              " 1.0,\n",
              " 361.0,\n",
              " 1.0,\n",
              " 307.0,\n",
              " 6.0,\n",
              " 604.0,\n",
              " 1.0,\n",
              " 2.0,\n",
              " 418.0,\n",
              " 422.0,\n",
              " 7.0,\n",
              " 34.0,\n",
              " 41.0,\n",
              " 167.0,\n",
              " 742.0,\n",
              " 3.0,\n",
              " 112.0,\n",
              " 207.0,\n",
              " 3.0,\n",
              " 338.0,\n",
              " 424.0,\n",
              " 5.0,\n",
              " 26.0,\n",
              " 13.0,\n",
              " 235.0,\n",
              " 8.0,\n",
              " 693.0,\n",
              " 4.0,\n",
              " 1821.0,\n",
              " 167.0,\n",
              " 2.0,\n",
              " 2.0,\n",
              " 216.0,\n",
              " 3.0,\n",
              " 66.0,\n",
              " 4.0,\n",
              " 130.0,\n",
              " 29.0,\n",
              " 2.0,\n",
              " 241.0,\n",
              " 2.0,\n",
              " 332.0,\n",
              " 2.0,\n",
              " 422.0,\n",
              " 9.0,\n",
              " 112.0,\n",
              " 743.0,\n",
              " 9.0,\n",
              " 39.0,\n",
              " 14000,\n",
              " 1840.0,\n",
              " 744.0,\n",
              " 5.0,\n",
              " 182.0,\n",
              " 3.0,\n",
              " 368.0,\n",
              " 1.0,\n",
              " 397.0,\n",
              " 6.0,\n",
              " 604.0,\n",
              " 1,\n",
              " 1821.0,\n",
              " 167.0,\n",
              " 745.0,\n",
              " 4.0,\n",
              " 746.0,\n",
              " 4.0,\n",
              " 210.0,\n",
              " 46.0,\n",
              " 747.0,\n",
              " 5.0,\n",
              " 5.0,\n",
              " 740.0,\n",
              " 1843.0,\n",
              " 284.0,\n",
              " 2019.0,\n",
              " 9.0,\n",
              " 1.0,\n",
              " 55.0,\n",
              " 266.0,\n",
              " 271.0,\n",
              " 1876.0,\n",
              " 2.0,\n",
              " 47.0,\n",
              " 362.0,\n",
              " 376.0,\n",
              " 1872.0,\n",
              " 3.0,\n",
              " 45.0,\n",
              " 329.0,\n",
              " 334.0,\n",
              " 1871.0,\n",
              " 4.0,\n",
              " 31.0,\n",
              " 526.0,\n",
              " 527.0,\n",
              " 1858.0,\n",
              " 5.0,\n",
              " 21.0,\n",
              " 333.0,\n",
              " 335.0,\n",
              " 1852.0,\n",
              " 6.0,\n",
              " 8.0,\n",
              " 145.0,\n",
              " 147.0,\n",
              " 1857.0,\n",
              " 7.0,\n",
              " 65.0,\n",
              " 256.0,\n",
              " 258.0,\n",
              " 3,\n",
              " 1880.0,\n",
              " 8.0,\n",
              " 4.0,\n",
              " 913.0,\n",
              " 914.0,\n",
              " 1887.0,\n",
              " 9.0,\n",
              " 103.0,\n",
              " 464.0,\n",
              " 1936.0,\n",
              " 3.0,\n",
              " 1.0,\n",
              " 9.0,\n",
              " 39.0,\n",
              " 1828.0,\n",
              " 2.0,\n",
              " 2.0,\n",
              " 5.0,\n",
              " 182.0,\n",
              " 1837.0,\n",
              " 2.0,\n",
              " 3.0,\n",
              " 9.0,\n",
              " 108.0,\n",
              " 1812.0,\n",
              " 6,\n",
              " 1,\n",
              " 2.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iJBeF0jrrA1",
        "outputId": "5f2bfbb4-a51d-4693-dffc-4c2ba4fa6165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import lexnlp.extract.en.citations\n",
        "print(list(lexnlp.extract.en.citations.get_citations(all_text)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(5, 'Ala.', 'Alabama Reports', 740, None, None, None), (5, 'Ala.', 'Alabama Reports', 740, '1843', None, None), (55, 'Ala.', 'Alabama Reports', 266, '271', None, None), (47, 'Ala.', 'Alabama Reports', 362, '376', None, None), (45, 'Ala.', 'Alabama Reports', 329, '334', None, None), (31, 'Ala.', 'Alabama Reports', 526, '527', None, None), (21, 'Ala.', 'Alabama Reports', 333, '335', None, None), (8, 'Cal.', 'California Reports', 145, '147', None, None), (65, 'Ala.', 'Alabama Reports', 256, '258', None, None), (4, 'S.W.', 'South Western Reporter', 913, '914', None, None), (103, 'A.L.R.', 'American Law Reports', 464, None, None, None), (9, 'Cow.', \"Cowen's Reports\", 39, None, None, None), (5, 'Port.', 'Alabama Reports, Porter', 182, None, None, None), (9, 'Johns.', \"Johnson's Reports\", 108, None, None, None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOrqKZ6Nr1sL",
        "outputId": "fed1f6cb-fdaa-4ff5-aeaa-da5a9eb8a4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.entities.nltk_re\n",
        "print(list(lexnlp.extract.en.entities.nltk_re.get_companies(all_text)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Lehman, Durr Co, (17983, 18001)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtaeIKwMr6PC",
        "outputId": "8ad7cf49-7bac-4ac0-c9dc-6e07c28ff647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import lexnlp.extract.en.conditions\n",
        "print(list(lexnlp.extract.en.conditions.get_conditions(all_text)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('until', '[2]\\nCreditors’ Remedies\\nLien and Priority\\nUnder St.1821, prohibiting a levy on a crop', ''), ('until', 'on a growing crop, nor does such lien attach', ''), ('if', 'It was proved by the claimants, by the production of a written contract, that Harrison, on the twenty-second of May, 1840, in consideration that the claimants were involved, as indorsers for Burton & Harrison of Sumter county, and were then exposed to an execution, amounting to upwards of fourteen thousand dollars, bargained and sold to the claimants all his growing crop of cotton &c., consisting of one hundred and twenty acres, &c. Allen Harrison promised and obliged himself to give up his crop to the use of the claimants at any time to save them from suffering as his indorsers;', ''), ('when', 'The claimants came from Tennessee, (where they resided) about the first of September, 1840, bringing with them three or four white laborers, and took possession of the crop and slaves, and with the latter, and white laborers, gathered the cotton, prepared it for market, and', ''), ('if', 'The court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that Harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but', ''), ('when', 'it was not, and the lien of the fieri facias would have attached upon it,', ''), ('if', 'gathered, yet', ''), ('not subject to', 'the claimants obtained possession on the first of September, and controlled the gathering of the crop, then no lien attached, and it was', ''), ('until', 'Rep, 693;] and', ''), ('until', '167,] which declares it to be lawful to levy an execution on a planted crop,', ''), ('if', 'It is admitted that the contract between the defendant in execution, and the claimants, was in good faith,', ''), ('when', 'The defendant in execution might at any time have divested the interest which the contract vested in the claimants, by discharging their liability as his indorsers, or a judgment creditor might have satisfied the lien, and', ''), ('unless', 'We will then consider the writing under which the claimants assert a right, as a mortgage with a power to take possession any time during the year,', ''), ('if', 'Conceding the truth of the facts stated in the bill of exceptions, and we think it will not follow, that the possession of the claimants is a nullity, and that the case must be considered as', ''), ('if', 'The contract contains an express undertaking to give up the crop at any time the claimants might require it for their indemnity, and', ''), ('if', 'they took possession of it in the absence of the grantor, (though without his consent,)', ''), ('if', 'he subsequently acquiesced in it, the inference would be,', ''), ('subject to', 'Mr. Dane, in remarking upon this point, says, “The American editor of Bacon’s Abridgment, says, ‘Wheat growing in the ground is a chattel, and', ''), ('until', 'The first section of the act of 1821, “To prevent sheriffs and other officers from levying executions in certain cases, enacts, that “It shall not be lawful for any sheriff or other officer, to levy a writ of fieri facias or other execution on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('until', 'Now here is an express inhibition to levy an execution on a crop while it remains on, or in the ground, and', ''), ('until', 'If so, the act cited, will only have the effect of keeping the right to levy it in abeyance', ''), ('if', 'The lien and the right to levy are intimately connected, and', ''), ('until', 'That it was competent for the legislature to have made it unlawful to levy an execution on particular property,', ''), ('until', 'If the object was merely to suspend the sale,', ''), ('as soon as', 'The idea that the lien attached upon the planted crop', ''), ('until', 'the execution was delivered to the sheriff, though the right to levy it was postponed', ''), ('if', 'They do not refer to the lien,', ''), ('until', 'they did they would postpone it', ''), ('until', 'the crop was gathered; but it is the levy they relate to and postpone', ''), ('until', '**4 The right to levy an execution on a planted crop, then, being expressly taken away by the statute, the lien which is connected with and consequent upon that right, never attaches', ''), ('if', 'The circuit judge may have mistaken the law in supposing that the contract was a sale, but', ''), ('when', 'There is no assumption of any material fact in the charge; but the possession of the claimant, the time', ''), ('if', 'acquired, the gathering of the crop, &c., are all referred to the determination of the jury; who are instructed,', ''), ('until', '**4 The statute which presents the question before the court is, that “it shall not be lawful for any sheriff or other officer to levy a writ of fieei facias or other execution, on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('subject to', 'The policy of the State, as indicated by these statutes, is undeniably that all the property of a debtor, real and personal, to which he has a legal title, shall be', ''), ('until', 'The mischief which the statute designed to remedy was, the sacrifice which would be necessarily made by the sale of an immature crop: the statute enables the debtor to retain it', ''), ('if', '**5', ''), ('until', 'The sheriff is forbidden to levy on a “planted crop”', ''), ('if', 'Now,', ''), ('until', 'This, I feel a thorough conviction, was not the intention of the legislature; but that it was to secure him from loss, by prohibiting a levy and sale of the crop,', ''), ('when', 'it was gathered,', ''), ('subject to', 'Growing crops as', ''), ('subject to', '464\\nGenerally, at common law, growing crops raised by annual planting, while still attached to the soil, are regarded as personal chattels,', ''), ('where', 'And', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3wejcwUsFpF",
        "outputId": "9ee92f66-a92f-4c20-978f-8fe53c9722f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import lexnlp.extract.en.constraints\n",
        "print(list(lexnlp.extract.en.constraints.get_constraints(all_text)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('after', 'on a growing crop, nor does such lien attach until', ''), ('after', '', ' and that alias and pluries fieri facias’, issued regularly up to the time levy was made; that the cotton levied on was growed on the plantation of harrison, and cultivated by the hands in his service.'), ('first of', 'the claimants came from tennessee, (where they resided) about the', ''), ('first of', 'the court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but if it was not, and the lien of the fieri facias would have attached upon it, when gathered, yet if the claimants obtained possession on the', ''), ('after', 'it merely inhibits the levy, but the lien attaches, and a levy and sale may be made', ''), ('more than', 'taking this to be clear *744 law, and it will be seen, that the defendant in execution at the time of the levy had nothing', ''), ('before', 'it has been frequently mooted whether, at common law, corn, &c.,', ''), ('before', '**4 the statute which presents the question', ''), ('after', 'now, if the view taken by the majority of the court, is correct, the right secured to the plaintiff in execution, of levying on the crop', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASLo3-sLvFvo",
        "outputId": "c8a0af1b-c804-47ff-852b-6d32b2cdb27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.copyright\n",
        "print(list(lexnlp.extract.en.copyright.get_copyright(all_text)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('©', '2019', 'Thomson Reuters. No')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZAAGORQvNSF",
        "outputId": "86af826f-a550-4baa-cf5e-4dab6ad11dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.courts\n",
        "court_config_data = []\n",
        "print(list(lexnlp.extract.en.courts.get_courts(all_text,court_config_data)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk_9N1Vjv5UD",
        "outputId": "d0772df1-9cee-493d-d598-a83042f0bc11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.cusip\n",
        "print(lexnlp.extract.en.cusip.get_cusip(all_text))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<generator object get_cusip at 0x7f53a9943308>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rof5GRD_wJ1m",
        "outputId": "091584aa-b98e-41f8-8566-304c3c34b59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import lexnlp.extract.en.dates\n",
        "print(list(lexnlp.extract.en.dates.get_dates(all_text)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[datetime.date(2020, 6, 1), datetime.date(1840, 11, 1), datetime.date(1839, 10, 1), datetime.date(1840, 9, 1), datetime.date(1840, 5, 1), datetime.date(1840, 5, 1), datetime.date(2020, 12, 1), datetime.date(2020, 12, 1), datetime.date(2020, 1, 1), datetime.date(2020, 1, 1), datetime.date(2020, 1, 1), datetime.date(2020, 3, 21), datetime.date(2020, 6, 1), datetime.date(2020, 7, 1), datetime.date(2020, 11, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJFtOXiFwRRF",
        "outputId": "aae11348-33a8-46b3-f3ec-45eb731310ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.definitions\n",
        "print(list(lexnlp.extract.en.definitions.get_definitions(all_text)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2aO_W7nwaJU",
        "outputId": "2b1365fe-ed14-423a-d72b-de605956eb93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.distances\n",
        "print(list(lexnlp.extract.en.distances.get_distances(all_text)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6zCLNeswm1g",
        "outputId": "36ae699f-fd4d-4ba5-8b87-319dd050f895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.durations\n",
        "print(list(lexnlp.extract.en.durations.get_durations(all_text)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('second', 20.0, 0.00023148148148148146), ('year', 6.0, 2190.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV5YiG-gwxcJ",
        "outputId": "61e194ef-681c-4c74-9000-ec885121ff65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.geoentities\n",
        "geo_config_list = []\n",
        "list(lexnlp.extract.en.geoentities.get_geoentities(all_text,geo_config_list))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7QsXyJrxLVa",
        "outputId": "d7fee33b-cf3c-4894-f908-e891be468d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.money\n",
        "print(list(lexnlp.extract.en.money.get_money(all_text)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(100.0, 'USD'), (14000, 'USD'), (14000, 'USD')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdgvNpxwxVBt",
        "outputId": "e4259a26-b6c7-49ad-fc74-6c0443b6a660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.percents\n",
        "print(list(lexnlp.extract.en.percents.get_percents(all_text)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XZcmRHcxdxI",
        "outputId": "fe8d0127-81ca-4734-be34-e536dfab715d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.pii\n",
        "print(list(lexnlp.extract.en.pii.get_pii(all_text)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a6Mgvuhxpha",
        "outputId": "9df96a0a-86d0-4688-8f69-e349563fa5cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.ratios\n",
        "print(list(lexnlp.extract.en.ratios.get_ratios(all_text)))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_uNh4hmx3Rp",
        "outputId": "af4b1408-603e-45be-8061-ec28a09ed9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.regulations\n",
        "print(list(lexnlp.extract.en.regulations.get_regulations(all_text)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcGdMP7vyALd",
        "outputId": "32200e8f-f5ac-46ad-ac12-e6fa23dd0d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.trademarks\n",
        "print(list(lexnlp.extract.en.trademarks.get_trademarks(all_text)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI9Lqm7TyFV-",
        "outputId": "8b03ff15-4557-4590-cf33-65b32e9d983d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import lexnlp.extract.en.urls\n",
        "print(list(lexnlp.extract.en.urls.get_urls(all_text)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEIMH7gQypEk",
        "outputId": "658ca795-3402-4ac2-fafe-7b702e61e112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "import lexnlp.extract.en.addresses\n",
        "print(list(lexnlp.extract.en.addresses.get_addresses(all_text)))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c3adb969cba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddresses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddresses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_addresses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'lexnlp.extract.en.addresses' has no attribute 'get_addresses'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc2NQxTlz5vI",
        "outputId": "2d502f8e-760a-4c7f-d31f-1de7d0828305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "import lexnlp.extract.en.persons\n",
        "print(list(lexnlp.extract.en.urls.get_persons(all_text)))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-764b59cb3079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_persons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lexnlp.extract.en.persons'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}