{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_09.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashanthdnss/Nithya_INFO5731_Fall2020/blob/master/In_class_exercise/In_class_exercise_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTMYS8rwm3uH"
      },
      "source": [
        "# **The ninth in-class-exercise (20 points in total, 11/11/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8BwGGibm3uP"
      },
      "source": [
        "The purpose of the exercise is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from here: https://github.com/unt-iialab/INFO5731_FALL2020/blob/master/In_class_exercise/exercise09_datacollection.zip. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwYCSiWIm3uR",
        "outputId": "6e572c3f-a23e-4f76-a807-d114e33a3bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "import pandas as pd \n",
        "import re \n",
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "  \n",
        "dataset = pd.read_csv(\"stsa-train.txt\", sep='delimiter', header=None) \n",
        "#dataset              \n",
        "dataset = pd.DataFrame(dataset) \n",
        "dataset.columns = [\"Text\"] \n",
        "dataset['Reviews'] = dataset['Text'].str.split(' ').str[0]\n",
        "#dataset  \n",
        "dataset['Text'] = dataset['Text'].str.split(n=1).str[1]\n",
        "dataset\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a stirring , funny and finally transporting re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apparently reassembled from the cutting-room f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>they presume their audience wo n't sit still f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this is a visually stunning rumination on love...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jonathan parker 's bartleby should have been t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6915</th>\n",
              "      <td>painful , horrifying and oppressively tragic ,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6916</th>\n",
              "      <td>take care is nicely performed by a quintet of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6917</th>\n",
              "      <td>the script covers huge , heavy topics in a bla...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6918</th>\n",
              "      <td>a seriously bad film with seriously warped log...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6919</th>\n",
              "      <td>a deliciously nonsensical comedy about a city ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6920 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Reviews\n",
              "0     a stirring , funny and finally transporting re...       1\n",
              "1     apparently reassembled from the cutting-room f...       0\n",
              "2     they presume their audience wo n't sit still f...       0\n",
              "3     this is a visually stunning rumination on love...       1\n",
              "4     jonathan parker 's bartleby should have been t...       1\n",
              "...                                                 ...     ...\n",
              "6915  painful , horrifying and oppressively tragic ,...       1\n",
              "6916  take care is nicely performed by a quintet of ...       0\n",
              "6917  the script covers huge , heavy topics in a bla...       0\n",
              "6918  a seriously bad film with seriously warped log...       0\n",
              "6919  a deliciously nonsensical comedy about a city ...       1\n",
              "\n",
              "[6920 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm1UomKkYstb",
        "outputId": "f5124c73-24ed-4dbb-9e12-ced939975ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "\n",
        "dataset_test = pd.read_csv(\"stsa-test.txt\", sep='delimiter', header=None)        \n",
        "dataset_test = pd.DataFrame(dataset_test) \n",
        "dataset_test.columns = [\"Text\"] \n",
        "dataset_test['Reviews'] = dataset_test['Text'].str.split(' ').str[0]\n",
        "#dataset  \n",
        "dataset_test['Text'] = dataset_test['Text'].str.split(n=1).str[1]\n",
        "dataset_test"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>no movement , no yuks , not much of anything .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a gob of drivel so sickly sweet , even the eag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gangs of new york is an unapologetic mess , wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we never really feel involved with the story ,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>this is one of polanski 's best films .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>an often-deadly boring , strange reading of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>the problem with concept films is that if the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1818</th>\n",
              "      <td>safe conduct , however ambitious and well-inte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>a film made with as little wit , interest , an...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1820</th>\n",
              "      <td>but here 's the real damn : it is n't funny , ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1821 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Reviews\n",
              "0        no movement , no yuks , not much of anything .       0\n",
              "1     a gob of drivel so sickly sweet , even the eag...       0\n",
              "2     gangs of new york is an unapologetic mess , wh...       0\n",
              "3     we never really feel involved with the story ,...       0\n",
              "4               this is one of polanski 's best films .       1\n",
              "...                                                 ...     ...\n",
              "1816  an often-deadly boring , strange reading of a ...       0\n",
              "1817  the problem with concept films is that if the ...       0\n",
              "1818  safe conduct , however ambitious and well-inte...       0\n",
              "1819  a film made with as little wit , interest , an...       0\n",
              "1820  but here 's the real damn : it is n't funny , ...       0\n",
              "\n",
              "[1821 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQnnfCUL-lv7",
        "outputId": "a500bafe-a1c5-4ac6-a703-1145a06948f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Cleaning of data, removing unnecessary noises.\n",
        "nltk.download('stopwords') \n",
        "  \n",
        "corpus_train = [] \n",
        "corpus_test = []\n",
        "  \n",
        "for i in range(0, 6920): \n",
        "    text = re.sub('[^a-zA-Z]', '', dataset['Text'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    corpus_train.append(text)\n",
        "\n",
        "for i in range(0, 1821): \n",
        "    text = re.sub('[^a-zA-Z]', '', dataset_test['Text'][i]) \n",
        "    text = text.lower() \n",
        "    text = text.split() \n",
        "    ps = PorterStemmer() \n",
        "    text = ''.join(text) \n",
        "    corpus_test.append(text)\n",
        "  \n",
        "#print(corpus_train)\n",
        "#print(corpus_test)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vraIcBcDEotX",
        "outputId": "f89c0a4e-c3a2-4903-dab8-a10112fd2027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# creating bag of words model \n",
        "cv = CountVectorizer(max_features = 1500) \n",
        "  \n",
        "X = cv.fit_transform(corpus_train).toarray() \n",
        "y = dataset.iloc[:, 1].values\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '0' '0' ... '0' '0' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snJHXAtWGyn2"
      },
      "source": [
        "# splitting the data set into training set and validation set \n",
        "from sklearn.model_selection import train_test_split \n",
        "  \n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 0) \n"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZby4NBQo4o"
      },
      "source": [
        "**(1) MultinominalNB**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_vqCEBZHd4u"
      },
      "source": [
        "# fitting naive bayes to the training set \n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "  \n",
        "classifier = MultinomialNB()\n",
        "model = classifier.fit(X_train, y_train) \n",
        "  \n"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRywXHAXH8Nk",
        "outputId": "de296430-bc32-4b35-a268-02828984c834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# predicting test set results \n",
        "y_pred = classifier.predict(X_val) \n",
        "y_pred\n",
        "  "
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '1', '1', ..., '1', '1', '1'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4krQEFWWzQXu",
        "outputId": "e6df23ab-8804-4309-9b79-4e915d3ec786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5346820809248555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T1C1Q4bNo_M"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=10)\n",
        "#for train, test in kf.split(dataset):\n",
        "#  print(\"%s %s\" % (train, test))"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dM-MYXwQiOp"
      },
      "source": [
        "**(2) SVM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0wgekbiPuzA"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "model_svm = clf.fit(X_train, y_train)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLtIIMbhSCC7",
        "outputId": "50e47b7d-7a07-4eaf-e66b-416d34963bc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = clf.predict(X_val)\n",
        "print(y_pred)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1' '1' '1' ... '1' '1' '1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XiIE8GnSinB",
        "outputId": "58e9bed2-ce5b-416d-bc3a-542973dbc19e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "s= model_svm.score(X_val, y_val)\n",
        "print(\"Accuracy:\", s )"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5346820809248555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG8XRhYImsTd"
      },
      "source": [
        "**(3) KNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3ARlk_GX5dR"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_val = scaler.transform(X_val)"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kupzSQB6oKJ4",
        "outputId": "fb5c147c-fdcf-4982-ab0b-5e6ec803219b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GhB8EMzoPIM",
        "outputId": "e7b98851-0d39-4741-81b5-b2983d385b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = classifier.predict(X_val)\n",
        "y_pred"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '0', '0', ..., '0', '0', '0'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHjUl60CqQrV",
        "outputId": "affd9ea1-06f6-4e3d-8938-f15d50d32693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[645   1]\n",
            " [736   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      1.00      0.64       646\n",
            "           1       0.67      0.00      0.01       738\n",
            "\n",
            "    accuracy                           0.47      1384\n",
            "   macro avg       0.57      0.50      0.32      1384\n",
            "weighted avg       0.57      0.47      0.30      1384\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7zu3Hh7q0Ov"
      },
      "source": [
        "**(4) Decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CneJWhwwq4gL"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRQakYXYuDU0",
        "outputId": "51303b9a-dd4d-421a-e7d0-a3ff3ba5d084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_val)\n",
        "y_pred"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '1', '1', ..., '1', '1', '1'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVl2VoAO2AVw",
        "outputId": "59ac5493-3cad-46db-9372-3d56aecee445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5346820809248555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQxsYIlu9qI9"
      },
      "source": [
        "**(5) Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Tjg5H69vNL",
        "outputId": "0358ec8b-cfc1-40bd-bf51-5782ca249812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Import Random Forest Model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred=clf.predict(X_val)\n",
        "y_pred"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '1', '1', ..., '1', '1', '1'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfhHoZigMKT5",
        "outputId": "915e3c25-ac61-46a0-acf6-6c8e61018ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5346820809248555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfMktRbNMjHV"
      },
      "source": [
        "**(6) XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dynRn-0oMhei"
      },
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
        "                max_depth = 5, alpha = 10, n_estimators = 10)"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_M_eyZIR_Mo",
        "outputId": "54d3f6a0-bec7-4172-9d19-fd4241dc2946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "xg_reg.fit(X_train,y_train)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[01:46:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=0.3, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=5, min_child_weight=1, missing=None, n_estimators=10,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JGdjlumSB79",
        "outputId": "8f6652ba-ccae-4618-b28b-6276532c143e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "preds = xg_reg.predict(X_test)\n",
        "preds"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5125731, 0.5125731, 0.5125731, ..., 0.5125731, 0.5125731,\n",
              "       0.5125731], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4tEeIPzSG1b",
        "outputId": "34bd2f6f-c476-42b0-86d2-15e45b751ea8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "print(\"RMSE: %f\" % (rmse))"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.499322\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}