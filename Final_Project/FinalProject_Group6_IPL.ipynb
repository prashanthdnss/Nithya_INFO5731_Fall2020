{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProject_Group6_IPL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLOxaaDfmeoz10CNNyxkLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashanthdnss/Nithya_INFO5731_Fall2020/blob/master/Final_Project/FinalProject_Group6_IPL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNE6LDzlCeav"
      },
      "source": [
        "Extracting Latest #IPL2020 tweets on 11/02/2020\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKmz_NDUCEjO",
        "outputId": "0651ef9c-bcf5-4e42-b2fa-1e6626a37bd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tweepy\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import tweepy\n",
        "import re\n",
        "import os\n",
        "#os.chdir(\"C:/Users/prash/OneDrive/Desktop/INFO 5731 Computational Methods/Assignments/Assignment 2/\")\n",
        "\n",
        "def twitter_hashtag(api_key, api_key_secret, access_token, access_token_secret, hashtag):\n",
        "    \n",
        "    auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
        "    auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "    api = tweepy.API(auth)\n",
        "    \n",
        "    file_name = '_'.join(re.findall(r\"#(\\w+)\", hashtag))\n",
        "\n",
        "    with open('%s.csv' % (file_name), 'w') as file:\n",
        "\n",
        "        w = csv.writer(file)\n",
        "\n",
        "        w.writerow(['tweet_text'])\n",
        "\n",
        "        for tweet in tweepy.Cursor(api.search, q=hashtag+' -filter:retweets', lang=\"en\", tweet_mode='extended').items(1000):\n",
        "            w.writerow([tweet.full_text.replace('\\n',' ').encode('utf-8')])\n",
        "            \n",
        "api_key = input('Please give twitter api key')\n",
        "api_key_secret = input('Please give twitter api key secret')\n",
        "access_token = input('Please give twitter access token')\n",
        "access_token_secret = input('Please give twitter access token secret')\n",
        "    \n",
        "hashtag = input('enter the hashtag')\n",
        "\n",
        "twitter_hashtag(api_key, api_key_secret, access_token, access_token_secret, hashtag)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Please give twitter api keyePjdnPqsmA5Mgjewf5i5Vtnuw\n",
            "Please give twitter api key secretV83Stor4JRihnxggUa9OODxIrAc8EHmQdJxlnpxAGZXjqbJA7v\n",
            "Please give twitter access token1287853629869821952-ZsnNF12Y53o5JfCOUBPn72lO0OJau1\n",
            "Please give twitter access token secretTSYcER5dl5L72dcbpo8f0LzQqfn6qX3r2n1QsLpOGxRAz\n",
            "enter the hashtag#IPL2020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEY6w0EcCcrE"
      },
      "source": [
        "#Keeping tweets in a Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYvmlYI7DAAc",
        "outputId": "16231559-8cd9-48e8-f191-42f26727f626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"IPL2020.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b\"Dropping Shami in WC SEMIS,Saini in yesterda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b\"IPL 2020: Here's what skipper Virat Kohli sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'@bharath1 and I chat about #RCBvsDC match, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'@KajariaCeramic Royal Challengers Bangalore ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'#IPLOnMC \\xf0\\x9f\\x8f\\x8f #RCBvsDC: Royal Ch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text\n",
              "0  b\"Dropping Shami in WC SEMIS,Saini in yesterda...\n",
              "1  b\"IPL 2020: Here's what skipper Virat Kohli sa...\n",
              "2  b'@bharath1 and I chat about #RCBvsDC match, w...\n",
              "3  b'@KajariaCeramic Royal Challengers Bangalore ...\n",
              "4  b'#IPLOnMC \\xf0\\x9f\\x8f\\x8f #RCBvsDC: Royal Ch..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S7TzBnXDQA7"
      },
      "source": [
        "Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8DgvDmFDNw0",
        "outputId": "eb78449b-a85d-4704-f761-24900fa446e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "#Remove noise\n",
        "df['tweet_text'] = df['tweet_text'].str.replace('[^\\w\\s]','')\n",
        "#df['tweet_text'].head()\n",
        "\n",
        "#Remove stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "df['tweet_text'] = df['tweet_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "df['tweet_text']\n",
        "\n",
        "#Remove  numbers\n",
        "df['tweet_text'] = df['tweet_text'].apply(lambda x: \" \".join(x for x in x.split() if not x.isdigit()))\n",
        "df['tweet_text']\n",
        "\n",
        "#lowercase\n",
        "df['tweet_text'] = df['tweet_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "df['tweet_text']\n",
        "\n",
        "#stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "df['tweet_text'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "\n",
        "#lemmatization\n",
        "!pip install -U textblob\n",
        "from textblob import Word\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "df['tweet_text'] = df['tweet_text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "df['tweet_text'].head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    bdropping shami wc semissaini yesterday match ...\n",
              "1    bipl here skipper virat kohli said royal chall...\n",
              "2    bbharath1 i chat rcbvsdc match rather tepid af...\n",
              "3    bkajariaceramic royal challenger bangalore sun...\n",
              "4    biplonmc xf0x9fx8fx8f rcbvsdc royal challenger...\n",
              "Name: tweet_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Y_cwqTD70W"
      },
      "source": [
        "df.to_csv('clean_tweets.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ijA4KdFLhv"
      },
      "source": [
        "https://github.com/prashanthdnss/Nithya_INFO5731_Fall2020/blob/master/Final_Project/clean_tweets.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chf4oC_SFOGh"
      },
      "source": [
        "https://github.com/prashanthdnss/Nithya_INFO5731_Fall2020/blob/master/Final_Project/IPL2020.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDdbKWgxFS-v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}